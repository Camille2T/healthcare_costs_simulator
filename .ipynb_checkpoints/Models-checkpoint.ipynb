{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,PolynomialFeatures, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import dill\n",
    "import math\n",
    "from sklearn import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpatients=pd.read_csv('prepared_data/Inpatient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local=pd.read_csv('prepared_data/Output_local_basis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals=pd.read_csv('prepared_data/hospitals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=local.merge(hospitals, left_on='zipcode2017', right_on='zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_inner=inpatients.merge(temp, left_on='prov_id', right_on='Facility ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['DRG','hrrnum','hosp_ownership','prov_id']\n",
    "numeric_columns=['average_AGI_c', 'average_wage_c','per_over_65','per_ba','per_h','Score' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = full_inner['average_covered_charges']\n",
    "X = full_inner.loc[:,categorical_columns+ numeric_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: with hospital fixed effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_0 = ['DRG', 'prov_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5605525619976106\n",
      "R^2 score on train data: 0.7981749042587953\n",
      "R^2 score on test data: 0.7897874718265723\n",
      "average error rate on test set:  0.33582241814272457\n",
      "average error  on test set:  16058.940547323824\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "features = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_columns_0)])\n",
    "\n",
    "est_0 = Pipeline([\n",
    "    ('features', features),\n",
    "    ('estimator', LinearRegression())])\n",
    "\n",
    "est_0.fit(X_train[categorical_columns_0], y_train)\n",
    "end = timer()\n",
    "\n",
    "print(end-start)\n",
    "print(f'R^2 score on train data: {est_0.score(X_train[categorical_columns_0], y_train)}')\n",
    "print(f'R^2 score on test data: {est_0.score(X_test[categorical_columns_0], y_test)}')\n",
    "\n",
    "y_pred=est_0.predict(X_test[categorical_columns_0])\n",
    "print('average error rate on test set: ', abs((y_pred-y_test)/y_test).mean())\n",
    "print('average error  on test set: ', abs((y_pred-y_test)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualEstimator(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self,n_estimators=100,min_samples_leaf=1000,max_features='auto'):\n",
    "        self.n_estimators=n_estimators\n",
    "        self.min_samples_leaf=min_samples_leaf\n",
    "        self.max_features=max_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        est_1=LinearRegression().fit(X, y)\n",
    "        res = y-est_1.predict(X)\n",
    "        est_2=RandomForestRegressor(min_samples_leaf=self.min_samples_leaf,\n",
    "                                    max_features=self.max_features,\n",
    "                                    n_estimators=self.n_estimators).fit(X, res)\n",
    "        self.estimator_1_=est_1\n",
    "        self.estimator_2_=est_2\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator_1_.predict(X)+self.estimator_2_.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_1 = ['DRG','hrrnum','hosp_ownership', 'prov_id']\n",
    "numeric_columns_1=['average_AGI_c', 'average_wage_c','per_over_65','per_ba','per_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DRG', 'hrrnum', 'hosp_ownership', 'prov_id', 'average_AGI_c',\n",
       "       'average_wage_c', 'per_over_65', 'per_ba', 'per_h', 'Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-6137b2613131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     ('estimator', ResidualEstimator(min_samples_leaf=200,n_estimators=100,max_features=\"auto\"))])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m est_1.fit(X_train[categorical_columns_1+numeric_columns_1], y_train\n\u001b[0m\u001b[1;32m     11\u001b[0m          \u001b[0;31m# , estimator__sample_weight=X_train['total_discharges']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m          )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-2c711ed19618>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mest_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mest_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         est_2=RandomForestRegressor(min_samples_leaf=self.min_samples_leaf,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                     \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                     n_estimators=self.n_estimators).fit(X, res)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \"\"\"\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "features = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_columns_1),\n",
    "('numeric', 'passthrough', numeric_columns_1)])\n",
    "\n",
    "est_1 = Pipeline([\n",
    "    ('features', features),\n",
    "    ('estimator', ResidualEstimator(min_samples_leaf=200,n_estimators=100,max_features=\"auto\"))])\n",
    "\n",
    "est_1.fit(X_train[categorical_columns_1+numeric_columns_1], y_train\n",
    "         # , estimator__sample_weight=X_train['total_discharges']\n",
    "         )\n",
    "end = timer()\n",
    "\n",
    "print(end-start)\n",
    "print(f'R^2 score on train data: {est_1.score(X_train[categorical_columns_1+numeric_columns_1], y_train)}')\n",
    "print(f'R^2 score on test data: {est_1.score(X_test[categorical_columns_1+numeric_columns_1], y_test)}')\n",
    "\n",
    "y_pred=est_1.predict(X_test[categorical_columns_1+numeric_columns_1])\n",
    "print('average error rate on test set: ', abs((y_pred-y_test)/y_test).mean())\n",
    "print('average error  on test set: ', abs((y_pred-y_test)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score on whole data: 0.8043417887554274\n"
     ]
    }
   ],
   "source": [
    "#Fit the model on the whole dataset\n",
    "est_1.fit(X[categorical_columns_1+numeric_columns_1], y)\n",
    "print(f'R^2 score on whole data: {est_1.score(X[categorical_columns_1+numeric_columns_1], y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(est_1,open('prepared_data/est_1.pkd', 'wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: without hospital fixed effects but with score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_inner_w_spending=full_inner[full_inner.Footnote.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = full_inner_w_spending['average_covered_charges']\n",
    "X_2 = full_inner_w_spending.loc[:,categorical_columns+ numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2, y_2 = shuffle(X_2, y_2)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_2 = ['DRG','hrrnum','hosp_ownership']\n",
    "numeric_columns_2=[ 'average_wage_c','per_over_65','Score','average_AGI_c','per_ba','per_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257.9405489549972\n",
      "R^2 score on train data: 0.7784160802705331\n",
      "R^2 score on test data: 0.7823530001811672\n",
      "average error rate on test set:  0.337502165135528\n",
      "average error  on test set:  16746.85284451546\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "features = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_columns_2),\n",
    "('numeric', 'passthrough', numeric_columns_2)])\n",
    "\n",
    "est_2 = Pipeline([\n",
    "    ('features', features),\n",
    "    ('estimator', ResidualEstimator(min_samples_leaf=150,n_estimators=100,max_features=\"auto\"))])\n",
    "\n",
    "est_2.fit(X_train_2[categorical_columns_2+numeric_columns_2], y_train_2\n",
    "         # , estimator__sample_weight=X_train['total_discharges']\n",
    "         )\n",
    "end = timer()\n",
    "\n",
    "print(end-start)\n",
    "print(f'R^2 score on train data: {est_2.score(X_train_2[categorical_columns_2+numeric_columns_2], y_train_2)}')\n",
    "print(f'R^2 score on test data: {est_2.score(X_test_2[categorical_columns_2+numeric_columns_2], y_test_2)}')\n",
    "\n",
    "y_pred_2=est_2.predict(X_test_2[categorical_columns_2+numeric_columns_2])\n",
    "print('average error rate on test set: ', abs((y_pred_2-y_test_2)/y_test_2).mean())\n",
    "print('average error  on test set: ', abs((y_pred_2-y_test_2)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['DRG', 'hrrnum',\n",
       "                                                   'hosp_ownership']),\n",
       "                                                 ('numeric', 'passthrough',\n",
       "                                                  ['average_wage_c',\n",
       "                                                   'per_over_65', 'Score',\n",
       "                                                   'average_AGI_c', 'per_ba',\n",
       "                                                   'per_h'])])),\n",
       "                ('estimator', ResidualEstimator(min_samples_leaf=150))])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_2.fit(X_2[categorical_columns_2+numeric_columns_2], y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(est_2,open('prepared_data/est_2.pkd', 'wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: without hospital fixed effects and without score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_3 = ['DRG','hrrnum','hosp_ownership']\n",
    "numeric_columns_3=[ 'average_wage_c','per_over_65','average_AGI_c','per_ba','per_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ColumnTransformer([\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_columns_3),\n",
    "('numeric', 'passthrough', numeric_columns_3)])\n",
    "\n",
    "est_3 = Pipeline([\n",
    "    ('features', features),\n",
    "    ('estimator', ResidualEstimator(min_samples_leaf=100,n_estimators=200,max_features=\"auto\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "est_3.fit(X_train[categorical_columns_3+numeric_columns_3], y_train\n",
    "         # , estimator__sample_weight=X_train['total_discharges']\n",
    "         )\n",
    "end = timer()\n",
    "\n",
    "print(end-start)\n",
    "print(f'R^2 score on train data: {est_3.score(X_train[categorical_columns_3+numeric_columns_3], y_train)}')\n",
    "print(f'R^2 score on test data: {est_3.score(X_test[categorical_columns_3+numeric_columns_3], y_test)}')\n",
    "\n",
    "y_pred=est_3.predict(X_test[categorical_columns_3+numeric_columns_3])\n",
    "print('average error rate on test set: ', abs((y_pred-y_test)/y_test).mean())\n",
    "print('average error  on test set: ', abs((y_pred-y_test)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['DRG', 'hrrnum',\n",
       "                                                   'hosp_ownership']),\n",
       "                                                 ('numeric', 'passthrough',\n",
       "                                                  ['average_wage_c',\n",
       "                                                   'per_over_65',\n",
       "                                                   'average_AGI_c', 'per_ba',\n",
       "                                                   'per_h'])])),\n",
       "                ('estimator',\n",
       "                 ResidualEstimator(min_samples_leaf=100, n_estimators=200))])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_3.fit(X[categorical_columns_3+numeric_columns_3], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(est_3,open('prepared_data/est_3.pkd', 'wb'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: combination of models 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comb_test=np.concatenate((np.reshape(est_1.predict(X_test_2[categorical_columns_1 + numeric_columns_1]), (-1,1)),\n",
    "                            np.reshape(est_2.predict(X_test_2[categorical_columns_2 + numeric_columns_2]), (-1,1))), axis=1)\n",
    "X_comb_train=np.concatenate((np.reshape(est_1.predict(X_train_2[categorical_columns_1 + numeric_columns_1]), (-1,1)),\n",
    "                             np.reshape(est_2.predict(X_train_2[categorical_columns_2 + numeric_columns_2]), (-1,1))), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error rate on the training set:  0.212563418032397\n",
      "average error on the training set:  12678.137187007032\n",
      "R^2 score using selected columns and transformers: 0.8748432393262726\n",
      "average error rate on the test set:  0.21287581962549526\n",
      "average error  on the test set:  12737.332542758293\n"
     ]
    }
   ],
   "source": [
    "est_4 = RandomForestRegressor(max_depth=6, random_state=0)\n",
    "est_4.fit(X_comb_train, y_train_2)\n",
    "\n",
    "print('average error rate on the training set: ',abs((est_4.predict(X_comb_train)-y_train_2)/y_train_2).mean())\n",
    "print('average error on the training set: ',abs((est_4.predict(X_comb_train)-y_train_2)).mean())\n",
    "\n",
    "print(f'R^2 score using selected columns and transformers: {est_4.score(X_comb_test, y_test_2)}')\n",
    "\n",
    "print('average error rate on the test set: ',abs((est_4.predict(X_comb_test)-y_test_2)/y_test_2).mean())\n",
    "print('average error  on the test set: ',abs((est_4.predict(X_comb_test)-y_test_2)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(est_4,open('prepared_data/est_4.pkd', 'wb'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models.ipynb\n",
      "Visualizations.ipynb\n",
      "prepared_data\n",
      "raw_inputs\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 4020101] add the app backbone, including the html pages, the app.py, the css file, and Dockerfile but no data\n",
      " 14 files changed, 1001 insertions(+)\n",
      " create mode 100644 Dockerfile\n",
      " create mode 100644 app/.DS_Store\n",
      " create mode 100644 app/app.py\n",
      " create mode 100644 app/conda-requirements.txt\n",
      " create mode 100644 app/requirements.txt\n",
      " create mode 100644 app/static/.DS_Store\n",
      " create mode 100644 app/static/style.css\n",
      " create mode 100644 app/templates/.DS_Store\n",
      " create mode 100644 app/templates/Model.html\n",
      " create mode 100644 app/templates/about2.html\n",
      " create mode 100644 app/templates/index.html\n",
      " create mode 100644 app/templates/index_2.html\n",
      " create mode 100644 app/templates/index_3.html\n",
      " create mode 100644 app/templates/results.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git commit -m 'add the app backbone, including the html pages, the app.py, the css file, and Dockerfile but no data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the list of variables for the app and the dataset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump((categorical_columns,numeric_columns,\n",
    "            categorical_columns_1,numeric_columns_1,\n",
    "           categorical_columns_2,numeric_columns_2,\n",
    "           categorical_columns_3,numeric_columns_3), open('prepared_data/cat_num_col.pkd', 'wb'))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the dataset for the app**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=local.merge(hospitals, left_on='zipcode2017', right_on='zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's incorporate the data from inpatient, just the information present or not\n",
    "\n",
    "inpatient_list_hosp=inpatients[['prov_id','prov_zip']].drop_duplicates()\n",
    "inpatient_list_hosp['Inpatients_avail']=1\n",
    "inpatient_list_hosp=inpatient_list_hosp[['prov_id','Inpatients_avail']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2=inpatient_list_hosp.merge(temp, how='right',left_on='prov_id',right_on='Facility ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2['Score']=temp_2.Score.apply(lambda x : float(x) if x != 'Not Available' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2['Score_avail']=temp_2.Footnote.apply(lambda x : 0 if x == None else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2['Inpatients_avail']=temp_2['Inpatients_avail'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2['hosp_category']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2.loc[(temp_2.Inpatients_avail==1)&(temp_2.Score_avail==0),'hosp_category']=1\n",
    "temp_2.loc[(temp_2.Inpatients_avail==1)&(temp_2.Score_avail==1),'hosp_category']=4\n",
    "temp_2.loc[(temp_2.Inpatients_avail==0)&(temp_2.Score_avail==0),'hosp_category']=3\n",
    "temp_2.loc[(temp_2.Inpatients_avail==0)&(temp_2.Score_avail==1),'hosp_category']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2.rename(columns={'City':'countyname',\n",
    "                    'Facility ID' : 'Provider ID'},\n",
    "           inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prov_id</th>\n",
       "      <th>Inpatients_avail</th>\n",
       "      <th>zipcode2017</th>\n",
       "      <th>hrrnum</th>\n",
       "      <th>county</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>average_AGI_c</th>\n",
       "      <th>average_wage_c</th>\n",
       "      <th>COUNTY_ID</th>\n",
       "      <th>per_over_65</th>\n",
       "      <th>per_ba</th>\n",
       "      <th>per_h</th>\n",
       "      <th>Provider ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Footnote</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>hosp_rating_fn</th>\n",
       "      <th>Score_avail</th>\n",
       "      <th>hosp_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3024.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>3168.0</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>262218.210859</td>\n",
       "      <td>0.960859</td>\n",
       "      <td>52093.619003</td>\n",
       "      <td>249.690657</td>\n",
       "      <td>28417.768308</td>\n",
       "      <td>37.312330</td>\n",
       "      <td>-91.799018</td>\n",
       "      <td>66.638548</td>\n",
       "      <td>55.641617</td>\n",
       "      <td>28417.768308</td>\n",
       "      <td>0.161957</td>\n",
       "      <td>0.131522</td>\n",
       "      <td>0.154186</td>\n",
       "      <td>262218.210859</td>\n",
       "      <td>0.986121</td>\n",
       "      <td>6.041667</td>\n",
       "      <td>52093.619003</td>\n",
       "      <td>16.054545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.921717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>161909.590674</td>\n",
       "      <td>0.193962</td>\n",
       "      <td>27818.339780</td>\n",
       "      <td>126.757860</td>\n",
       "      <td>15989.995363</td>\n",
       "      <td>5.094979</td>\n",
       "      <td>15.090129</td>\n",
       "      <td>23.910746</td>\n",
       "      <td>16.767326</td>\n",
       "      <td>15989.995363</td>\n",
       "      <td>0.040010</td>\n",
       "      <td>0.137957</td>\n",
       "      <td>0.164017</td>\n",
       "      <td>161909.590674</td>\n",
       "      <td>0.080031</td>\n",
       "      <td>5.936582</td>\n",
       "      <td>27818.339780</td>\n",
       "      <td>2.205973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>19.526845</td>\n",
       "      <td>-161.880060</td>\n",
       "      <td>4.811600</td>\n",
       "      <td>27.336667</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>10001.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>110114.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30119.250000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>13154.500000</td>\n",
       "      <td>33.680992</td>\n",
       "      <td>-97.508440</td>\n",
       "      <td>51.639582</td>\n",
       "      <td>44.518386</td>\n",
       "      <td>13154.500000</td>\n",
       "      <td>0.134672</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.038820</td>\n",
       "      <td>110114.500000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30119.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250084.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48840.500000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>28100.000000</td>\n",
       "      <td>37.766329</td>\n",
       "      <td>-87.875455</td>\n",
       "      <td>61.173231</td>\n",
       "      <td>51.938428</td>\n",
       "      <td>28100.000000</td>\n",
       "      <td>0.157918</td>\n",
       "      <td>0.085894</td>\n",
       "      <td>0.087132</td>\n",
       "      <td>250084.500000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>48840.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>390120.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>76241.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>42056.500000</td>\n",
       "      <td>41.070054</td>\n",
       "      <td>-81.175125</td>\n",
       "      <td>76.795411</td>\n",
       "      <td>62.346322</td>\n",
       "      <td>42056.500000</td>\n",
       "      <td>0.182523</td>\n",
       "      <td>0.191344</td>\n",
       "      <td>0.223079</td>\n",
       "      <td>390120.000000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>76241.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>670130.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99801.000000</td>\n",
       "      <td>457.000000</td>\n",
       "      <td>56041.000000</td>\n",
       "      <td>64.835070</td>\n",
       "      <td>-68.002160</td>\n",
       "      <td>264.815267</td>\n",
       "      <td>146.194817</td>\n",
       "      <td>56041.000000</td>\n",
       "      <td>0.569440</td>\n",
       "      <td>0.854172</td>\n",
       "      <td>0.963230</td>\n",
       "      <td>670130.000000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>99801.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             prov_id  Inpatients_avail   zipcode2017       hrrnum  \\\n",
       "count    3168.000000       3168.000000   3168.000000  3168.000000   \n",
       "mean   262218.210859          0.960859  52093.619003   249.690657   \n",
       "std    161909.590674          0.193962  27818.339780   126.757860   \n",
       "min     10001.000000          0.000000   1040.000000     1.000000   \n",
       "25%    110114.500000          1.000000  30119.250000   144.000000   \n",
       "50%    250084.500000          1.000000  48840.500000   268.000000   \n",
       "75%    390120.000000          1.000000  76241.000000   357.000000   \n",
       "max    670130.000000          1.000000  99801.000000   457.000000   \n",
       "\n",
       "             county     Latitude    Longitude  average_AGI_c  average_wage_c  \\\n",
       "count   3168.000000  3168.000000  3168.000000    3168.000000     3168.000000   \n",
       "mean   28417.768308    37.312330   -91.799018      66.638548       55.641617   \n",
       "std    15989.995363     5.094979    15.090129      23.910746       16.767326   \n",
       "min     1001.000000    19.526845  -161.880060       4.811600       27.336667   \n",
       "25%    13154.500000    33.680992   -97.508440      51.639582       44.518386   \n",
       "50%    28100.000000    37.766329   -87.875455      61.173231       51.938428   \n",
       "75%    42056.500000    41.070054   -81.175125      76.795411       62.346322   \n",
       "max    56041.000000    64.835070   -68.002160     264.815267      146.194817   \n",
       "\n",
       "          COUNTY_ID  per_over_65       per_ba        per_h    Provider ID  \\\n",
       "count   3168.000000  3168.000000  3168.000000  3168.000000    3168.000000   \n",
       "mean   28417.768308     0.161957     0.131522     0.154186  262218.210859   \n",
       "std    15989.995363     0.040010     0.137957     0.164017  161909.590674   \n",
       "min     1001.000000     0.047665     0.000831     0.006673   10001.000000   \n",
       "25%    13154.500000     0.134672     0.028352     0.038820  110114.500000   \n",
       "50%    28100.000000     0.157918     0.085894     0.087132  250084.500000   \n",
       "75%    42056.500000     0.182523     0.191344     0.223079  390120.000000   \n",
       "max    56041.000000     0.569440     0.854172     0.963230  670130.000000   \n",
       "\n",
       "             Score    Footnote       zipcode  hosp_rating_fn  Score_avail  \\\n",
       "count  3024.000000  144.000000   3168.000000      330.000000       3168.0   \n",
       "mean      0.986121    6.041667  52093.619003       16.054545          1.0   \n",
       "std       0.080031    5.936582  27818.339780        2.205973          0.0   \n",
       "min       0.480000    1.000000   1040.000000        5.000000          1.0   \n",
       "25%       0.940000    1.000000  30119.250000       16.000000          1.0   \n",
       "50%       0.990000    5.000000  48840.500000       16.000000          1.0   \n",
       "75%       1.030000    5.000000  76241.000000       16.000000          1.0   \n",
       "max       1.530000   19.000000  99801.000000       23.000000          1.0   \n",
       "\n",
       "       hosp_category  \n",
       "count    3168.000000  \n",
       "mean        3.921717  \n",
       "std         0.387924  \n",
       "min         2.000000  \n",
       "25%         4.000000  \n",
       "50%         4.000000  \n",
       "75%         4.000000  \n",
       "max         4.000000  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_2['prov_id']=temp_2['Provider ID']\n",
    "temp_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3168 entries, 0 to 3167\n",
      "Data columns (total 18 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   hosp_name       3168 non-null   object \n",
      " 1   zipcode         3168 non-null   int64  \n",
      " 2   state           3168 non-null   object \n",
      " 3   Latitude        3168 non-null   float64\n",
      " 4   Longitude       3168 non-null   float64\n",
      " 5   Provider ID     3168 non-null   int64  \n",
      " 6   countyname      3168 non-null   object \n",
      " 7   hosp_rating     3168 non-null   object \n",
      " 8   average_AGI_c   3168 non-null   float64\n",
      " 9   average_wage_c  3168 non-null   float64\n",
      " 10  per_over_65     3168 non-null   float64\n",
      " 11  per_ba          3168 non-null   float64\n",
      " 12  per_h           3168 non-null   float64\n",
      " 13  Score           3024 non-null   float64\n",
      " 14  hrrnum          3168 non-null   int64  \n",
      " 15  hosp_ownership  3168 non-null   object \n",
      " 16  prov_id         3168 non-null   int64  \n",
      " 17  hosp_category   3168 non-null   int64  \n",
      "dtypes: float64(8), int64(5), object(5)\n",
      "memory usage: 470.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#['Provider ID', 'DRG', 'prov_id', 'total_discharges', 'countyname']\n",
    "\n",
    "X_full=temp_2[['hosp_name','zipcode','state','Latitude','Longitude','Provider ID','countyname','hosp_rating' ]\n",
    "                                      +numeric_columns +['hrrnum', 'hosp_ownership', 'prov_id','hosp_category']]\n",
    "X_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(X_full, open('prepared_data/X_full.pkd', 'wb'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-279-8a92de76533e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_full['price']=0\n"
     ]
    }
   ],
   "source": [
    "X_full['price']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3168 entries, 0 to 3167\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   hosp_name       3168 non-null   object \n",
      " 1   zipcode         3168 non-null   int64  \n",
      " 2   state           3168 non-null   object \n",
      " 3   Latitude        3168 non-null   float64\n",
      " 4   Longitude       3168 non-null   float64\n",
      " 5   Provider ID     3168 non-null   int64  \n",
      " 6   countyname      3168 non-null   object \n",
      " 7   hosp_rating     3168 non-null   object \n",
      " 8   average_AGI_c   3168 non-null   float64\n",
      " 9   average_wage_c  3168 non-null   float64\n",
      " 10  per_over_65     3168 non-null   float64\n",
      " 11  per_ba          3168 non-null   float64\n",
      " 12  per_h           3168 non-null   float64\n",
      " 13  Score           3024 non-null   float64\n",
      " 14  hrrnum          3168 non-null   int64  \n",
      " 15  hosp_ownership  3168 non-null   object \n",
      " 16  prov_id         3168 non-null   int64  \n",
      " 17  hosp_category   3168 non-null   int64  \n",
      " 18  price           3168 non-null   int64  \n",
      "dtypes: float64(8), int64(6), object(5)\n",
      "memory usage: 495.0+ KB\n"
     ]
    }
   ],
   "source": [
    "X_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-280-b82296119d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhosp_category\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mest_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhosp_category\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategorical_columns_1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mnumeric_columns_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1287\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cap_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;31m# just raising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "X_full.loc[X_full.hosp_category==1,'price']=est_1.predict(X_full.loc[X_full.hosp_category==1,categorical_columns_1+ numeric_columns_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
